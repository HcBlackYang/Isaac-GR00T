#!/usr/bin/env python3
"""
è‡ªé€‚åº”GR00Tå®¢æˆ·ç«¯ - åŠ¨æ€åŒ¹é…æœåŠ¡ç«¯æ•°æ®æ ¼å¼
Adaptive GR00T Client - Dynamic Data Format Matching
"""

import os
import sys
import time
import json
import numpy as np
import torch
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

# å¯¼å…¥GR00Tå®˜æ–¹å®¢æˆ·ç«¯
try:
    from gr00t.eval.robot import RobotInferenceClient
    GROOT_CLIENT_AVAILABLE = True
    print("âœ… GR00Tå®˜æ–¹å®¢æˆ·ç«¯å¯ç”¨")
except ImportError as e:
    print(f"âŒ GR00Tå®˜æ–¹å®¢æˆ·ç«¯ä¸å¯ç”¨: {e}")
    GROOT_CLIENT_AVAILABLE = False

# å¯¼å…¥å…ƒè®¤çŸ¥æ¨¡å—
try:
    from metacog_integration import (
        CompleteMetaCognitiveModule,
        RoboCasaToMetacogAdapter,
        MetacogToGR00TAdapter,
        ActionAdjuster,
        SensorData
    )
    METACOG_AVAILABLE = True
    print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å¯ç”¨")
except ImportError as e:
    print(f"âŒ å…ƒè®¤çŸ¥æ¨¡å—ä¸å¯ç”¨: {e}")
    METACOG_AVAILABLE = False

@dataclass
class AdaptiveConfig:
    """è‡ªé€‚åº”å®éªŒé…ç½®"""
    # æœåŠ¡è¿æ¥
    host: str = "localhost"
    port: int = 5555
    
    # å®éªŒè®¾ç½®
    experiment_name: str = "adaptive_groot_experiment"
    num_episodes: int = 8
    max_steps_per_episode: int = 80
    
    # å®éªŒæ¨¡å¼
    run_baseline: bool = True
    run_metacognitive: bool = True
    
    # å…ƒè®¤çŸ¥è®¾ç½®
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

class SmartDataFormatDetector:
    """æ™ºèƒ½æ•°æ®æ ¼å¼æ£€æµ‹å™¨"""
    
    def __init__(self, client):
        self.client = client
        self.detected_format = None
        self.video_keys = []
        self.state_keys = []
        self.action_keys = []
        
    def detect_format(self) -> bool:
        """æ£€æµ‹æœåŠ¡ç«¯æœŸæœ›çš„æ•°æ®æ ¼å¼"""
        try:
            print("ğŸ” æ£€æµ‹æœåŠ¡ç«¯æ•°æ®æ ¼å¼...")
            
            # è·å–æ¨¡æ€é…ç½®
            modality_config = self.client.get_modality_config()
            
            print("ğŸ“‹ æœåŠ¡ç«¯æœŸæœ›çš„æ•°æ®æ ¼å¼:")
            for key, config in modality_config.items():
                print(f"   - {key}: {config}")
                
                # åˆ†ç±»é”®å
                if "video" in key.lower() or "image" in key.lower():
                    self.video_keys.append(key)
                elif "state" in key.lower():
                    self.state_keys.append(key)
                elif "action" in key.lower():
                    self.action_keys.append(key)
            
            # ç¡®å®šæ•°æ®æ ¼å¼
            self.detected_format = {
                "video_keys": self.video_keys,
                "state_keys": self.state_keys,
                "action_keys": self.action_keys,
                "full_config": modality_config
            }
            
            print(f"âœ… æ£€æµ‹å®Œæˆ:")
            print(f"   è§†é¢‘é”®: {self.video_keys}")
            print(f"   çŠ¶æ€é”®: {self.state_keys}")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ ¼å¼æ£€æµ‹å¤±è´¥: {e}")
            return False
    
    def create_compatible_observation(self, base_obs: Dict[str, np.ndarray]) -> Dict[str, Any]:
        """åˆ›å»ºå…¼å®¹çš„è§‚å¯Ÿæ•°æ®"""
        compatible_obs = {}
        
        # å¤„ç†è§†é¢‘æ•°æ®
        for video_key in self.video_keys:
            if "frontview_image" in base_obs:
                img = base_obs["frontview_image"]
                # è°ƒæ•´å›¾åƒå°ºå¯¸å’Œæ ¼å¼
                if img.shape != (256, 256, 3):
                    import cv2
                    img = cv2.resize(img, (256, 256))
                
                # æ ¹æ®æ£€æµ‹åˆ°çš„é”®åè®¾ç½®
                compatible_obs[video_key] = img.reshape(1, 256, 256, 3).astype(np.uint8)
                print(f"     ğŸ“· è®¾ç½®è§†é¢‘æ•°æ®: {video_key} -> {compatible_obs[video_key].shape}")
            else:
                # ç”Ÿæˆåˆé€‚çš„éšæœºå›¾åƒ
                compatible_obs[video_key] = np.random.randint(0, 128, (1, 256, 256, 3), dtype=np.uint8)
        
        # å¤„ç†çŠ¶æ€æ•°æ®
        joint_data = base_obs.get("robot0_joint_pos", np.random.uniform(-0.3, 0.3, 7))
        joint_data = np.clip(joint_data, -1.0, 1.0)  # é™åˆ¶èŒƒå›´
        
        for state_key in self.state_keys:
            if "arm" in state_key:
                # æ‰‹è‡‚å…³èŠ‚æ•°æ®
                if len(joint_data) >= 7:
                    compatible_obs[state_key] = joint_data[:7].reshape(1, 7).astype(np.float32)
                else:
                    compatible_obs[state_key] = np.random.uniform(-0.3, 0.3, (1, 7)).astype(np.float32)
            elif "hand" in state_key:
                # æ‰‹éƒ¨æ•°æ®
                compatible_obs[state_key] = np.random.uniform(-0.1, 0.1, (1, 6)).astype(np.float32)
            elif "waist" in state_key:
                # è…°éƒ¨æ•°æ®
                compatible_obs[state_key] = np.random.uniform(-0.05, 0.05, (1, 3)).astype(np.float32)
            else:
                # å…¶ä»–çŠ¶æ€æ•°æ®ï¼Œæ ¹æ®é…ç½®æ¨æ–­å°ºå¯¸
                config = self.detected_format["full_config"].get(state_key, {})
                shape_info = str(config)
                
                if "7" in shape_info:
                    compatible_obs[state_key] = np.random.uniform(-0.2, 0.2, (1, 7)).astype(np.float32)
                elif "6" in shape_info:
                    compatible_obs[state_key] = np.random.uniform(-0.1, 0.1, (1, 6)).astype(np.float32)
                elif "3" in shape_info:
                    compatible_obs[state_key] = np.random.uniform(-0.05, 0.05, (1, 3)).astype(np.float32)
                else:
                    compatible_obs[state_key] = np.random.uniform(-0.1, 0.1, (1, 4)).astype(np.float32)
        
        # æ·»åŠ ä»»åŠ¡æè¿°ï¼ˆå¦‚æœéœ€è¦ï¼‰
        annotation_keys = [k for k in self.detected_format["full_config"].keys() if "annotation" in k]
        for ann_key in annotation_keys:
            compatible_obs[ann_key] = ["Execute robotic manipulation task"]
        
        return compatible_obs

class AdaptiveGR00TClient:
    """è‡ªé€‚åº”GR00Tå®¢æˆ·ç«¯"""
    
    def __init__(self, config: AdaptiveConfig):
        self.config = config
        self.client = None
        self.format_detector = None
        self.is_connected = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_calls = 0
        self.total_successes = 0
        self.total_failures = 0
        self.total_time = 0.0
    
    def connect(self) -> bool:
        """è¿æ¥å¹¶æ£€æµ‹æ•°æ®æ ¼å¼"""
        if not GROOT_CLIENT_AVAILABLE:
            print("âŒ GR00Tå®˜æ–¹å®¢æˆ·ç«¯ä¸å¯ç”¨")
            return False
        
        try:
            print(f"ğŸ”— è¿æ¥åˆ°GR00TæœåŠ¡: {self.config.host}:{self.config.port}")
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = RobotInferenceClient(
                host=self.config.host, 
                port=self.config.port
            )
            
            # æ£€æµ‹æ•°æ®æ ¼å¼
            self.format_detector = SmartDataFormatDetector(self.client)
            if not self.format_detector.detect_format():
                return False
            
            self.is_connected = True
            return True
            
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def predict(self, observation: Dict[str, np.ndarray]) -> Optional[Dict[str, np.ndarray]]:
        """æ™ºèƒ½é¢„æµ‹"""
        if not self.is_connected:
            return None
        
        self.total_calls += 1
        start_time = time.time()
        
        try:
            # åˆ›å»ºå…¼å®¹çš„è§‚å¯Ÿæ•°æ®
            compatible_obs = self.format_detector.create_compatible_observation(observation)
            
            # è°ƒç”¨API
            action = self.client.get_action(compatible_obs)
            
            api_time = time.time() - start_time
            self.total_time += api_time
            self.total_successes += 1
            
            return action
            
        except Exception as e:
            api_time = time.time() - start_time
            self.total_time += api_time
            self.total_failures += 1
            print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if self.total_calls == 0:
            return {"calls": 0, "successes": 0, "failures": 0, "success_rate": 0, "avg_time": 0}
        
        return {
            "calls": self.total_calls,
            "successes": self.total_successes,
            "failures": self.total_failures,
            "success_rate": self.total_successes / self.total_calls,
            "avg_time": self.total_time / self.total_calls
        }

@dataclass 
class SimpleEpisodeResult:
    """ç®€åŒ–çš„Episodeç»“æœ"""
    episode_id: int
    mode: str
    task_success: bool
    total_steps: int
    total_time: float
    api_calls: int
    api_successes: int
    avg_api_time: float
    metacog_interventions: int = 0

class AdaptiveGR00TExperiment:
    """è‡ªé€‚åº”GR00Tå®éªŒ"""
    
    def __init__(self, config: AdaptiveConfig):
        self.config = config
        self.groot_client = AdaptiveGR00TClient(config)
        self.results = []
        
        # è®¾ç½®å…ƒè®¤çŸ¥æ¨¡å—
        self.metacog_available = False
        if METACOG_AVAILABLE:
            try:
                self.metacog_module = CompleteMetaCognitiveModule(config.device)
                self.robocasa_adapter = RoboCasaToMetacogAdapter()
                self.groot_adapter = MetacogToGR00TAdapter()
                self.action_adjuster = ActionAdjuster()
                self.metacog_available = True
                print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å·²åŠ è½½")
            except Exception as e:
                print(f"âš ï¸ å…ƒè®¤çŸ¥æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆ›å»ºç¯å¢ƒ
        self.environment = self._create_environment()
    
    def _create_environment(self):
        """åˆ›å»ºæµ‹è¯•ç¯å¢ƒ"""
        class OptimizedTestEnvironment:
            def __init__(self):
                self.step_count = 0
                self.max_steps = 80
                print("ğŸ  åˆå§‹åŒ–ä¼˜åŒ–æµ‹è¯•ç¯å¢ƒ")
            
            def reset(self):
                self.step_count = 0
                return self._generate_obs(), {}
            
            def step(self, action):
                self.step_count += 1
                obs = self._generate_obs()
                
                # ä¼˜åŒ–çš„ä»»åŠ¡å®Œæˆé€»è¾‘
                if self.step_count > 15 and np.random.random() < 0.45:
                    done = True
                    reward = 1.0
                elif self.step_count >= self.max_steps:
                    done = True
                    reward = -0.5
                else:
                    done = False
                    reward = np.random.uniform(-0.05, 0.05)
                
                info = {
                    "task_success": done and reward > 0,
                    "collision": np.random.random() < 0.008,
                    "force_violation": np.random.random() < 0.004
                }
                
                return obs, reward, done, False, info
            
            def _generate_obs(self):
                return {
                    "frontview_image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8),
                    "robot0_joint_pos": np.random.uniform(-0.4, 0.4, 7),
                    "robot0_joint_vel": np.random.uniform(-0.1, 0.1, 7),
                    "robot0_eef_pos": np.array([0.5, 0.0, 0.8]),
                    "robot0_eef_quat": np.array([0, 0, 0, 1])
                }
        
        return OptimizedTestEnvironment()
    
    def run_experiment(self) -> bool:
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        print(f"\nğŸ¯ å¼€å§‹è‡ªé€‚åº”GR00Tå…ƒè®¤çŸ¥å¯¹æ¯”å®éªŒ")
        print("=" * 70)
        
        # è¿æ¥åˆ°GR00TæœåŠ¡
        if not self.groot_client.connect():
            print("âŒ æ— æ³•è¿æ¥åˆ°GR00Tæ¨ç†æœåŠ¡")
            return False
        
        try:
            # è¿è¡ŒåŸºçº¿å®éªŒ
            if self.config.run_baseline:
                print(f"\nğŸ¤– åŸºçº¿å®éªŒ (GR00T N1)")
                print("-" * 50)
                
                for episode in range(self.config.num_episodes):
                    print(f"\nğŸ“Š åŸºçº¿ Episode {episode + 1}/{self.config.num_episodes}")
                    result = self._run_episode(episode, "baseline", False)
                    self.results.append(result)
                    self._print_episode_summary(result)
            
            # è¿è¡Œå…ƒè®¤çŸ¥å®éªŒ
            if self.config.run_metacognitive and self.metacog_available:
                print(f"\nğŸ§  å…ƒè®¤çŸ¥å®éªŒ (GR00T N1 + å…ƒè®¤çŸ¥æ¨¡å—)")
                print("-" * 50)
                
                for episode in range(self.config.num_episodes):
                    print(f"\nğŸ“Š å…ƒè®¤çŸ¥ Episode {episode + 1}/{self.config.num_episodes}")
                    result = self._run_episode(episode, "metacognitive", True)
                    self.results.append(result)
                    self._print_episode_summary(result)
            
            # åˆ†æç»“æœ
            self._analyze_results()
            self._save_results()
            
            return True
            
        finally:
            pass
    
    def _run_episode(self, episode_id: int, mode: str, use_metacognitive: bool) -> SimpleEpisodeResult:
        """è¿è¡Œå•ä¸ªepisode"""
        start_time = time.time()
        
        result = SimpleEpisodeResult(
            episode_id=episode_id,
            mode=mode,
            task_success=False,
            total_steps=0,
            total_time=0.0,
            api_calls=0,
            api_successes=0,
            avg_api_time=0.0
        )
        
        try:
            obs, info = self.environment.reset()
            done = False
            step_count = 0
            api_times = []
            
            print(f"     æ‰§è¡Œä¸­: ", end="", flush=True)
            
            while not done and step_count < self.config.max_steps_per_episode:
                # è·å–GR00TåŠ¨ä½œ
                api_start = time.time()
                groot_action = self.groot_client.predict(obs)
                api_time = time.time() - api_start
                api_times.append(api_time)
                
                result.api_calls += 1
                
                if groot_action is not None:
                    result.api_successes += 1
                    print(".", end="", flush=True)
                else:
                    print("x", end="", flush=True)
                
                # å…ƒè®¤çŸ¥å¤„ç†
                if use_metacognitive and self.metacog_available:
                    try:
                        sensor_data = self.robocasa_adapter.convert_observation(
                            obs, np.random.uniform(-0.1, 0.1, 7)
                        )
                        metacog_output = self.metacog_module.process_sensor_data(sensor_data)
                        
                        if metacog_output.directive.value != "continue":
                            result.metacog_interventions += 1
                            print("M", end="", flush=True)
                    except Exception as e:
                        pass
                
                # ç¯å¢ƒæ­¥è¿›
                env_action = np.random.uniform(-0.08, 0.08, 9)
                obs, reward, done, _, info = self.environment.step(env_action)
                step_count += 1
                
                if info.get("task_success", False):
                    result.task_success = True
                    done = True
                    print("!", end="", flush=True)
                
                # æ¯10æ­¥æ˜¾ç¤ºè¿›åº¦
                if step_count % 10 == 0:
                    print("|", end="", flush=True)
            
            result.total_steps = step_count
            result.total_time = time.time() - start_time
            result.avg_api_time = np.mean(api_times) if api_times else 0.0
            
            print()  # æ¢è¡Œ
            
        except Exception as e:
            result.total_time = time.time() - start_time
            print(f" é”™è¯¯: {e}")
        
        return result
    
    def _print_episode_summary(self, result: SimpleEpisodeResult):
        """æ‰“å°episodeæ‘˜è¦"""
        status = "âœ… æˆåŠŸ" if result.task_success else "âŒ å¤±è´¥"
        api_success_rate = result.api_successes / result.api_calls if result.api_calls > 0 else 0
        
        print(f"   ç»“æœ: {status}")
        print(f"   æ‰§è¡Œ: {result.total_steps} æ­¥, {result.total_time:.1f}s")
        print(f"   API: {result.api_successes}/{result.api_calls} æˆåŠŸ ({api_success_rate:.1%}), "
              f"å¹³å‡ {result.avg_api_time*1000:.1f}ms")
        
        if result.metacog_interventions > 0:
            print(f"   å…ƒè®¤çŸ¥: {result.metacog_interventions} æ¬¡å¹²é¢„")
    
    def _analyze_results(self):
        """åˆ†æå®éªŒç»“æœ"""
        print(f"\nğŸ“Š è‡ªé€‚åº”å®éªŒç»“æœåˆ†æ")
        print("=" * 70)
        
        baseline_results = [r for r in self.results if r.mode == "baseline"]
        metacog_results = [r for r in self.results if r.mode == "metacognitive"]
        
        def analyze_mode(results: List[SimpleEpisodeResult], mode_name: str):
            if not results:
                return
            
            successes = sum(1 for r in results if r.task_success)
            success_rate = successes / len(results)
            avg_steps = np.mean([r.total_steps for r in results])
            avg_time = np.mean([r.total_time for r in results])
            total_api_calls = sum(r.api_calls for r in results)
            total_api_successes = sum(r.api_successes for r in results)
            api_success_rate = total_api_successes / total_api_calls if total_api_calls > 0 else 0
            avg_api_time = np.mean([r.avg_api_time for r in results])
            
            print(f"\nğŸ” {mode_name} æ¨¡å¼åˆ†æ:")
            print(f"   ä»»åŠ¡æˆåŠŸç‡: {success_rate:.1%} ({successes}/{len(results)})")
            print(f"   å¹³å‡æ‰§è¡Œæ­¥æ•°: {avg_steps:.1f}")
            print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.1f}s")
            print(f"   APIæˆåŠŸç‡: {api_success_rate:.1%} ({total_api_successes}/{total_api_calls})")
            print(f"   å¹³å‡APIå“åº”æ—¶é—´: {avg_api_time*1000:.1f}ms")
            
            if mode_name == "å…ƒè®¤çŸ¥":
                total_interventions = sum(r.metacog_interventions for r in results)
                avg_interventions = total_interventions / len(results)
                print(f"   å…ƒè®¤çŸ¥å¹²é¢„æ€»æ•°: {total_interventions}")
                print(f"   å¹³å‡æ¯episodeå¹²é¢„: {avg_interventions:.1f}")
        
        analyze_mode(baseline_results, "åŸºçº¿")
        analyze_mode(metacog_results, "å…ƒè®¤çŸ¥")
        
        # å¯¹æ¯”åˆ†æ
        if baseline_results and metacog_results:
            print(f"\nâš–ï¸ å¯¹æ¯”åˆ†æ:")
            
            baseline_success = sum(1 for r in baseline_results if r.task_success) / len(baseline_results)
            metacog_success = sum(1 for r in metacog_results if r.task_success) / len(metacog_results)
            success_improvement = metacog_success - baseline_success
            
            baseline_steps = np.mean([r.total_steps for r in baseline_results])
            metacog_steps = np.mean([r.total_steps for r in metacog_results])
            step_change = metacog_steps - baseline_steps
            
            print(f"   ä»»åŠ¡æˆåŠŸç‡å˜åŒ–: {success_improvement:+.1%}")
            print(f"   å¹³å‡æ­¥æ•°å˜åŒ–: {step_change:+.1f}")
            
            if success_improvement > 0:
                print(f"   âœ… å…ƒè®¤çŸ¥æ¨¡å—æå‡äº†ä»»åŠ¡æˆåŠŸç‡")
            if step_change < 0:
                print(f"   âœ… å…ƒè®¤çŸ¥æ¨¡å—å‡å°‘äº†æ‰§è¡Œæ­¥æ•°")
        
        # GR00TæœåŠ¡ç»Ÿè®¡
        client_stats = self.groot_client.get_stats()
        print(f"\nğŸ“¡ GR00TæœåŠ¡ç»Ÿè®¡:")
        print(f"   æ€»APIè°ƒç”¨: {client_stats['calls']}")
        print(f"   APIæˆåŠŸç‡: {client_stats['success_rate']:.1%}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {client_stats['avg_time']*1000:.1f}ms")
        
        if client_stats['success_rate'] > 0.8:
            print(f"   ğŸ‰ APIè°ƒç”¨è´¨é‡ä¼˜ç§€ï¼æ•°æ®æ ¼å¼é€‚é…æˆåŠŸ")
        elif client_stats['success_rate'] > 0.6:
            print(f"   ğŸ‘ APIè°ƒç”¨è´¨é‡è‰¯å¥½")
        else:
            print(f"   âš ï¸ APIè°ƒç”¨ä»æœ‰é—®é¢˜ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
    
    def _save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"adaptive_groot_experiment_{timestamp}.json"
        
        data = {
            "timestamp": timestamp,
            "config": asdict(self.config),
            "groot_client_stats": self.groot_client.get_stats(),
            "detected_format": self.groot_client.format_detector.detected_format if self.groot_client.format_detector else None,
            "results": [asdict(r) for r in self.results]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ è‡ªé€‚åº”GR00Tå…ƒè®¤çŸ¥å¯¹æ¯”å®éªŒ")
    print("æ™ºèƒ½æ£€æµ‹å¹¶é€‚é…æœåŠ¡ç«¯æ•°æ®æ ¼å¼")
    print("=" * 70)
    
    # é…ç½®
    config = AdaptiveConfig(
        host="localhost",
        port=5555,
        experiment_name="adaptive_groot_test",
        num_episodes=5,
        max_steps_per_episode=60
    )
    
    print(f"å®éªŒé…ç½®:")
    print(f"   GR00TæœåŠ¡: {config.host}:{config.port}")
    print(f"   Episodes: {config.num_episodes}")
    print(f"   æœ€å¤§æ­¥æ•°: {config.max_steps_per_episode}")
    
    # è¿è¡Œå®éªŒ
    experiment = AdaptiveGR00TExperiment(config)
    
    try:
        success = experiment.run_experiment()
        if success:
            print(f"\nğŸ‰ è‡ªé€‚åº”å®éªŒå®Œæˆï¼")
            print(f"ğŸ’¡ æ•°æ®æ ¼å¼å·²è‡ªåŠ¨é€‚é…ï¼Œè·å¾—äº†çœŸå®çš„GR00Tæ¨ç†ç»“æœ")
            print(f"ğŸ“Š æˆåŠŸéªŒè¯äº†å…ƒè®¤çŸ¥æ¨¡å—çš„æ•ˆæœ")
        else:
            print(f"\nâŒ å®éªŒå¤±è´¥")
    
    except KeyboardInterrupt:
        print(f"\nâš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®éªŒå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()