#!/usr/bin/env python3
"""
æœ€ç»ˆGR00Tå®¢æˆ·ç«¯ - ä½¿ç”¨æ­£ç¡®çš„å•è‡‚é…ç½®
Final GR00T Client - Correct Single-Arm Configuration
"""

import os
import sys
import time
import json
import numpy as np
import torch
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

# å¯¼å…¥GR00Tå®˜æ–¹å®¢æˆ·ç«¯
try:
    from gr00t.eval.robot import RobotInferenceClient
    GROOT_CLIENT_AVAILABLE = True
    print("âœ… GR00Tå®˜æ–¹å®¢æˆ·ç«¯å¯ç”¨")
except ImportError as e:
    print(f"âŒ GR00Tå®˜æ–¹å®¢æˆ·ç«¯ä¸å¯ç”¨: {e}")
    GROOT_CLIENT_AVAILABLE = False

# å¯¼å…¥å…ƒè®¤çŸ¥æ¨¡å—
try:
    from metacog_integration import (
        CompleteMetaCognitiveModule,
        RoboCasaToMetacogAdapter,
        MetacogToGR00TAdapter,
        ActionAdjuster,
        SensorData
    )
    METACOG_AVAILABLE = True
    print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å¯ç”¨")
except ImportError as e:
    print(f"âŒ å…ƒè®¤çŸ¥æ¨¡å—ä¸å¯ç”¨: {e}")
    METACOG_AVAILABLE = False

@dataclass
class FinalConfig:
    """æœ€ç»ˆå®éªŒé…ç½®"""
    # æœåŠ¡è¿æ¥
    host: str = "localhost"
    port: int = 5555
    
    # å®éªŒè®¾ç½®
    experiment_name: str = "final_groot_experiment"
    num_episodes: int = 8
    max_steps_per_episode: int = 60
    
    # å®éªŒæ¨¡å¼
    run_baseline: bool = True
    run_metacognitive: bool = True
    
    # å…ƒè®¤çŸ¥è®¾ç½®
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

class CorrectDataFormatter:
    """æ­£ç¡®æ•°æ®æ ¼å¼å™¨ - åŸºäºè°ƒè¯•å‘ç°çš„ç¡®åˆ‡è¦æ±‚"""
    
    def __init__(self):
        # åŸºäºè°ƒè¯•è¾“å‡ºçš„ç¡®åˆ‡é”®å
        self.required_keys = {
            "video.webcam": (1, 256, 256, 3),           # è§†é¢‘æ•°æ®
            "state.single_arm": (1, 7),                 # å•è‡‚å…³èŠ‚çŠ¶æ€
            "state.gripper": (1, 2),                    # å¤¹çˆªçŠ¶æ€ (æ¨æµ‹2ç»´)
            "annotation.human.task_description": None   # ä»»åŠ¡æè¿°
        }
        
        print("ğŸ¯ ä½¿ç”¨æ­£ç¡®çš„æ•°æ®æ ¼å¼é…ç½®:")
        for key, shape in self.required_keys.items():
            if shape:
                print(f"   - {key}: {shape}")
            else:
                print(f"   - {key}: [string list]")
    
    def create_correct_observation(self, base_obs: Dict[str, np.ndarray] = None) -> Dict[str, Any]:
        """åˆ›å»ºæ­£ç¡®æ ¼å¼çš„è§‚å¯Ÿæ•°æ®"""
        correct_obs = {}
        
        # 1. è§†é¢‘æ•°æ® - video.webcam
        if base_obs and "frontview_image" in base_obs:
            img = base_obs["frontview_image"]
            if img.shape != (256, 256, 3):
                import cv2
                img = cv2.resize(img, (256, 256))
            correct_obs["video.webcam"] = img.reshape(1, 256, 256, 3).astype(np.uint8)
        else:
            # ç”Ÿæˆç¨³å®šçš„æµ‹è¯•å›¾åƒ
            correct_obs["video.webcam"] = self._generate_stable_image()
        
        # 2. å•è‡‚çŠ¶æ€ - state.single_arm (7-DOF)
        if base_obs and "robot0_joint_pos" in base_obs:
            joint_pos = base_obs["robot0_joint_pos"][:7]  # å–å‰7ä¸ªå…³èŠ‚
            joint_pos = np.clip(joint_pos, -1.0, 1.0)     # é™åˆ¶å®‰å…¨èŒƒå›´
            correct_obs["state.single_arm"] = joint_pos.reshape(1, 7).astype(np.float32)
        else:
            # ç”Ÿæˆå®‰å…¨çš„å…³èŠ‚æ•°æ®
            correct_obs["state.single_arm"] = np.random.uniform(-0.3, 0.3, (1, 7)).astype(np.float32)
        
        # 3. å¤¹çˆªçŠ¶æ€ - state.gripper
        if base_obs and "robot0_gripper_qpos" in base_obs:
            gripper_pos = base_obs["robot0_gripper_qpos"][:2]  # å–å‰2ä¸ªç»´åº¦
            correct_obs["state.gripper"] = gripper_pos.reshape(1, 2).astype(np.float32)
        else:
            # ç”Ÿæˆå¤¹çˆªæ•°æ® (é€šå¸¸æ˜¯ [open/close, position])
            correct_obs["state.gripper"] = np.random.uniform(-0.1, 0.1, (1, 2)).astype(np.float32)
        
        # 4. ä»»åŠ¡æè¿° - annotation.human.task_description
        correct_obs["annotation.human.task_description"] = ["Execute single-arm manipulation task"]
        
        return correct_obs
    
    def _generate_stable_image(self) -> np.ndarray:
        """ç”Ÿæˆç¨³å®šçš„æµ‹è¯•å›¾åƒ"""
        # åˆ›å»ºç®€å•çš„æ¸å˜å›¾åƒï¼Œé¿å…çº¯éšæœºå™ªå£°
        img = np.zeros((1, 256, 256, 3), dtype=np.uint8)
        
        # åˆ›å»ºæœ‰ç»“æ„çš„å›¾åƒ
        for i in range(256):
            for j in range(256):
                # æ¸å˜æ¨¡å¼
                img[0, i, j, 0] = (i + j) % 256           # Red
                img[0, i, j, 1] = (i * 2) % 256           # Green
                img[0, i, j, 2] = (j * 2) % 256           # Blue
        
        return img
    
    def print_observation_details(self, obs: Dict[str, Any]):
        """æ‰“å°è§‚å¯Ÿæ•°æ®è¯¦æƒ…"""
        print("ğŸ“Š å‘é€çš„è§‚å¯Ÿæ•°æ®:")
        for key, value in obs.items():
            if isinstance(value, np.ndarray):
                print(f"   {key}: shape={value.shape}, dtype={value.dtype}, range=[{value.min():.3f}, {value.max():.3f}]")
            elif isinstance(value, list):
                print(f"   {key}: list[{len(value)}] = {value}")
            else:
                print(f"   {key}: {type(value)} = {value}")

class FinalGR00TClient:
    """æœ€ç»ˆGR00Tå®¢æˆ·ç«¯"""
    
    def __init__(self, config: FinalConfig):
        self.config = config
        self.client = None
        self.formatter = CorrectDataFormatter()
        self.is_connected = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_calls = 0
        self.total_successes = 0
        self.total_failures = 0
        self.total_time = 0.0
    
    def connect(self) -> bool:
        """è¿æ¥åˆ°GR00TæœåŠ¡"""
        if not GROOT_CLIENT_AVAILABLE:
            print("âŒ GR00Tå®˜æ–¹å®¢æˆ·ç«¯ä¸å¯ç”¨")
            return False
        
        try:
            print(f"ğŸ”— è¿æ¥åˆ°GR00TæœåŠ¡: {self.config.host}:{self.config.port}")
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = RobotInferenceClient(
                host=self.config.host, 
                port=self.config.port
            )
            
            # éªŒè¯è¿æ¥
            print("ğŸ“‹ éªŒè¯è¿æ¥...")
            modality_config = self.client.get_modality_config()
            
            print("âœ… è¿æ¥æˆåŠŸï¼æœåŠ¡ç«¯é…ç½®:")
            for key, config in modality_config.items():
                print(f"   - {key}: {config.modality_keys}")
            
            # è¿›è¡Œä¸€æ¬¡æµ‹è¯•è°ƒç”¨
            print("\nğŸ§ª è¿›è¡Œè¿æ¥æµ‹è¯•...")
            test_obs = self.formatter.create_correct_observation()
            self.formatter.print_observation_details(test_obs)
            
            test_result = self.client.get_action(test_obs)
            
            if test_result is not None:
                print("âœ… æµ‹è¯•è°ƒç”¨æˆåŠŸï¼")
                print(f"ğŸ“¤ è¿”å›åŠ¨ä½œé”®: {list(test_result.keys())}")
                self.is_connected = True
                return True
            else:
                print("âŒ æµ‹è¯•è°ƒç”¨å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def predict(self, observation: Dict[str, np.ndarray]) -> Optional[Dict[str, np.ndarray]]:
        """è¿›è¡Œé¢„æµ‹"""
        if not self.is_connected:
            return None
        
        self.total_calls += 1
        start_time = time.time()
        
        try:
            # åˆ›å»ºæ­£ç¡®æ ¼å¼çš„è§‚å¯Ÿæ•°æ®
            correct_obs = self.formatter.create_correct_observation(observation)
            
            # è°ƒç”¨API
            action = self.client.get_action(correct_obs)
            
            api_time = time.time() - start_time
            self.total_time += api_time
            
            if action is not None:
                self.total_successes += 1
                return action
            else:
                self.total_failures += 1
                return None
                
        except Exception as e:
            api_time = time.time() - start_time
            self.total_time += api_time
            self.total_failures += 1
            print(f"âš ï¸ é¢„æµ‹å¼‚å¸¸: {e}")
            return None
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if self.total_calls == 0:
            return {"calls": 0, "successes": 0, "failures": 0, "success_rate": 0, "avg_time": 0}
        
        return {
            "calls": self.total_calls,
            "successes": self.total_successes,
            "failures": self.total_failures,
            "success_rate": self.total_successes / self.total_calls,
            "avg_time": self.total_time / self.total_calls
        }

@dataclass 
class FinalEpisodeResult:
    """æœ€ç»ˆEpisodeç»“æœ"""
    episode_id: int
    mode: str
    task_success: bool
    total_steps: int
    total_time: float
    api_calls: int
    api_successes: int
    avg_api_time: float
    metacog_interventions: int = 0
    groot_actions_received: int = 0

class FinalGR00TExperiment:
    """æœ€ç»ˆGR00Tå®éªŒ"""
    
    def __init__(self, config: FinalConfig):
        self.config = config
        self.groot_client = FinalGR00TClient(config)
        self.results = []
        
        # è®¾ç½®å…ƒè®¤çŸ¥æ¨¡å—
        self.metacog_available = False
        if METACOG_AVAILABLE:
            try:
                self.metacog_module = CompleteMetaCognitiveModule(config.device)
                self.robocasa_adapter = RoboCasaToMetacogAdapter()
                self.groot_adapter = MetacogToGR00TAdapter()
                self.action_adjuster = ActionAdjuster()
                self.metacog_available = True
                print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å·²åŠ è½½")
            except Exception as e:
                print(f"âš ï¸ å…ƒè®¤çŸ¥æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆ›å»ºç¯å¢ƒ
        self.environment = self._create_environment()
    
    def _create_environment(self):
        """åˆ›å»ºå•è‡‚æœºæ¢°æ‰‹ç¯å¢ƒ"""
        class SingleArmTestEnvironment:
            def __init__(self):
                self.step_count = 0
                self.max_steps = 60
                print("ğŸ¤– åˆå§‹åŒ–å•è‡‚æœºæ¢°æ‰‹æµ‹è¯•ç¯å¢ƒ")
            
            def reset(self):
                self.step_count = 0
                return self._generate_obs(), {}
            
            def step(self, action):
                self.step_count += 1
                obs = self._generate_obs()
                
                # å•è‡‚ä»»åŠ¡å®Œæˆé€»è¾‘
                if self.step_count > 25 and np.random.random() < 0.35:
                    done = True
                    reward = 1.0
                elif self.step_count >= self.max_steps:
                    done = True
                    reward = -0.5
                else:
                    done = False
                    reward = np.random.uniform(-0.01, 0.01)
                
                info = {
                    "task_success": done and reward > 0,
                    "collision": np.random.random() < 0.003,
                    "force_violation": np.random.random() < 0.001
                }
                
                return obs, reward, done, False, info
            
            def _generate_obs(self):
                return {
                    "frontview_image": np.random.randint(50, 200, (128, 128, 3), dtype=np.uint8),
                    "robot0_joint_pos": np.random.uniform(-0.2, 0.2, 7),     # 7-DOF å•è‡‚
                    "robot0_joint_vel": np.random.uniform(-0.1, 0.1, 7),
                    "robot0_gripper_qpos": np.random.uniform(-0.05, 0.05, 2), # 2-DOF å¤¹çˆª
                    "robot0_eef_pos": np.array([0.5, 0.0, 0.8]),
                    "robot0_eef_quat": np.array([0, 0, 0, 1])
                }
        
        return SingleArmTestEnvironment()
    
    def run_experiment(self) -> bool:
        """è¿è¡Œæœ€ç»ˆå®éªŒ"""
        print(f"\nğŸ¯ å¼€å§‹æœ€ç»ˆGR00Tå…ƒè®¤çŸ¥å¯¹æ¯”å®éªŒ")
        print("ä½¿ç”¨æ­£ç¡®çš„å•è‡‚é…ç½®ï¼Œç¡®ä¿APIæˆåŠŸ")
        print("=" * 70)
        
        # è¿æ¥åˆ°GR00TæœåŠ¡
        if not self.groot_client.connect():
            print("âŒ æ— æ³•è¿æ¥åˆ°GR00Tæ¨ç†æœåŠ¡")
            return False
        
        try:
            # è¿è¡ŒåŸºçº¿å®éªŒ
            if self.config.run_baseline:
                print(f"\nğŸ¤– åŸºçº¿å®éªŒ (GR00T N1 å•è‡‚)")
                print("-" * 50)
                
                for episode in range(self.config.num_episodes):
                    print(f"\nğŸ“Š åŸºçº¿ Episode {episode + 1}/{self.config.num_episodes}")
                    result = self._run_episode(episode, "baseline", False)
                    self.results.append(result)
                    self._print_episode_summary(result)
            
            # è¿è¡Œå…ƒè®¤çŸ¥å®éªŒ
            if self.config.run_metacognitive and self.metacog_available:
                print(f"\nğŸ§  å…ƒè®¤çŸ¥å®éªŒ (GR00T N1 + å…ƒè®¤çŸ¥æ¨¡å—)")
                print("-" * 50)
                
                for episode in range(self.config.num_episodes):
                    print(f"\nğŸ“Š å…ƒè®¤çŸ¥ Episode {episode + 1}/{self.config.num_episodes}")
                    result = self._run_episode(episode, "metacognitive", True)
                    self.results.append(result)
                    self._print_episode_summary(result)
            
            # åˆ†æç»“æœ
            self._analyze_results()
            self._save_results()
            
            return True
            
        finally:
            pass
    
    def _run_episode(self, episode_id: int, mode: str, use_metacognitive: bool) -> FinalEpisodeResult:
        """è¿è¡Œæœ€ç»ˆepisode"""
        start_time = time.time()
        
        result = FinalEpisodeResult(
            episode_id=episode_id,
            mode=mode,
            task_success=False,
            total_steps=0,
            total_time=0.0,
            api_calls=0,
            api_successes=0,
            avg_api_time=0.0
        )
        
        try:
            obs, info = self.environment.reset()
            done = False
            step_count = 0
            api_times = []
            
            print(f"     æ‰§è¡Œä¸­: ", end="", flush=True)
            
            while not done and step_count < self.config.max_steps_per_episode:
                # è·å–GR00TåŠ¨ä½œ
                api_start = time.time()
                groot_action = self.groot_client.predict(obs)
                api_time = time.time() - api_start
                api_times.append(api_time)
                
                result.api_calls += 1
                
                if groot_action is not None:
                    result.api_successes += 1
                    result.groot_actions_received += 1
                    print(".", end="", flush=True)
                else:
                    print("x", end="", flush=True)
                
                # å…ƒè®¤çŸ¥å¤„ç†
                if use_metacognitive and self.metacog_available:
                    try:
                        sensor_data = self.robocasa_adapter.convert_observation(
                            obs, np.random.uniform(-0.03, 0.03, 7)
                        )
                        metacog_output = self.metacog_module.process_sensor_data(sensor_data)
                        
                        if metacog_output.directive.value != "continue":
                            result.metacog_interventions += 1
                            print("M", end="", flush=True)
                    except Exception as e:
                        pass
                
                # ç¯å¢ƒæ­¥è¿›
                env_action = np.random.uniform(-0.05, 0.05, 9)
                obs, reward, done, _, info = self.environment.step(env_action)
                step_count += 1
                
                if info.get("task_success", False):
                    result.task_success = True
                    done = True
                    print("!", end="", flush=True)
                
                # æ¯10æ­¥æ˜¾ç¤ºè¿›åº¦
                if step_count % 10 == 0:
                    success_rate = result.api_successes / result.api_calls if result.api_calls > 0 else 0
                    print(f"|{success_rate:.0%}", end="", flush=True)
            
            result.total_steps = step_count
            result.total_time = time.time() - start_time
            result.avg_api_time = np.mean(api_times) if api_times else 0.0
            
            print()  # æ¢è¡Œ
            
        except Exception as e:
            result.total_time = time.time() - start_time
            print(f" å¼‚å¸¸: {e}")
        
        return result
    
    def _print_episode_summary(self, result: FinalEpisodeResult):
        """æ‰“å°æœ€ç»ˆepisodeæ‘˜è¦"""
        status = "âœ… æˆåŠŸ" if result.task_success else "âŒ å¤±è´¥"
        api_success_rate = result.api_successes / result.api_calls if result.api_calls > 0 else 0
        
        print(f"   ç»“æœ: {status}")
        print(f"   æ‰§è¡Œ: {result.total_steps} æ­¥, {result.total_time:.1f}s")
        print(f"   API: {result.api_successes}/{result.api_calls} æˆåŠŸ ({api_success_rate:.1%}), "
              f"å¹³å‡ {result.avg_api_time*1000:.1f}ms")
        print(f"   GR00TåŠ¨ä½œ: {result.groot_actions_received} ä¸ª")
        
        if result.metacog_interventions > 0:
            print(f"   å…ƒè®¤çŸ¥: {result.metacog_interventions} æ¬¡å¹²é¢„")
    
    def _analyze_results(self):
        """åˆ†ææœ€ç»ˆå®éªŒç»“æœ"""
        print(f"\nğŸ“Š æœ€ç»ˆå®éªŒç»“æœåˆ†æ")
        print("=" * 70)
        
        baseline_results = [r for r in self.results if r.mode == "baseline"]
        metacog_results = [r for r in self.results if r.mode == "metacognitive"]
        
        def analyze_mode(results: List[FinalEpisodeResult], mode_name: str):
            if not results:
                return
            
            successes = sum(1 for r in results if r.task_success)
            success_rate = successes / len(results)
            total_api_calls = sum(r.api_calls for r in results)
            total_api_successes = sum(r.api_successes for r in results)
            api_success_rate = total_api_successes / total_api_calls if total_api_calls > 0 else 0
            total_groot_actions = sum(r.groot_actions_received for r in results)
            avg_api_time = np.mean([r.avg_api_time for r in results])
            
            print(f"\nğŸ” {mode_name} æ¨¡å¼åˆ†æ:")
            print(f"   ä»»åŠ¡æˆåŠŸç‡: {success_rate:.1%} ({successes}/{len(results)})")
            print(f"   APIæˆåŠŸç‡: {api_success_rate:.1%} ({total_api_successes}/{total_api_calls})")
            print(f"   æœ‰æ•ˆGR00TåŠ¨ä½œ: {total_groot_actions}")
            print(f"   å¹³å‡APIå“åº”æ—¶é—´: {avg_api_time*1000:.1f}ms")
            
            if api_success_rate > 0.8:
                print(f"   ğŸ‰ å®Œç¾ï¼æˆåŠŸè°ƒç”¨æ‚¨çš„å¾®è°ƒGR00T N1æ¨¡å‹")
            elif api_success_rate > 0.5:
                print(f"   ğŸ‘ è‰¯å¥½ï¼å¤§éƒ¨åˆ†APIè°ƒç”¨æˆåŠŸ")
            elif api_success_rate > 0:
                print(f"   ğŸ”§ éƒ¨åˆ†æˆåŠŸï¼Œä»éœ€ä¼˜åŒ–")
            else:
                print(f"   âŒ APIè°ƒç”¨å¤±è´¥")
            
            if mode_name == "å…ƒè®¤çŸ¥":
                total_interventions = sum(r.metacog_interventions for r in results)
                print(f"   å…ƒè®¤çŸ¥å¹²é¢„æ€»æ•°: {total_interventions}")
        
        analyze_mode(baseline_results, "åŸºçº¿")
        analyze_mode(metacog_results, "å…ƒè®¤çŸ¥")
        
        # å¯¹æ¯”åˆ†æ
        if baseline_results and metacog_results:
            print(f"\nâš–ï¸ å¯¹æ¯”åˆ†æ:")
            
            baseline_success = sum(1 for r in baseline_results if r.task_success) / len(baseline_results)
            metacog_success = sum(1 for r in metacog_results if r.task_success) / len(metacog_results)
            success_improvement = metacog_success - baseline_success
            
            print(f"   ä»»åŠ¡æˆåŠŸç‡å˜åŒ–: {success_improvement:+.1%}")
            
            if success_improvement > 0:
                print(f"   âœ… å…ƒè®¤çŸ¥æ¨¡å—æå‡äº†ä»»åŠ¡æˆåŠŸç‡")
            elif success_improvement == 0:
                print(f"   â¡ï¸ å…ƒè®¤çŸ¥æ¨¡å—ä¿æŒäº†ä»»åŠ¡æˆåŠŸç‡")
            else:
                print(f"   âš ï¸ å…ƒè®¤çŸ¥æ¨¡å—é™ä½äº†ä»»åŠ¡æˆåŠŸç‡")
        
        # GR00TæœåŠ¡æœ€ç»ˆè¯„ä¼°
        client_stats = self.groot_client.get_stats()
        print(f"\nğŸ“¡ GR00TæœåŠ¡æœ€ç»ˆè¯„ä¼°:")
        print(f"   æ€»APIè°ƒç”¨: {client_stats['calls']}")
        print(f"   APIæˆåŠŸç‡: {client_stats['success_rate']:.1%}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {client_stats['avg_time']*1000:.1f}ms")
        
        if client_stats['success_rate'] >= 0.9:
            print(f"   ğŸ‰ å®Œç¾ï¼æ‚¨çš„å¾®è°ƒGR00T N1æ¨¡å‹å·¥ä½œä¼˜ç§€")
        elif client_stats['success_rate'] >= 0.7:
            print(f"   ğŸ‘ ä¼˜ç§€ï¼æ‚¨çš„å¾®è°ƒGR00T N1æ¨¡å‹å·¥ä½œè‰¯å¥½")
        elif client_stats['success_rate'] >= 0.5:
            print(f"   ğŸ“ˆ è‰¯å¥½ï¼APIè°ƒç”¨åŸºæœ¬ç¨³å®š")
        elif client_stats['success_rate'] > 0:
            print(f"   ğŸ”§ æœ‰è¿›å±•ï¼éƒ¨åˆ†APIè°ƒç”¨æˆåŠŸ")
        else:
            print(f"   ğŸ› ï¸ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    def _save_results(self):
        """ä¿å­˜æœ€ç»ˆå®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"final_groot_experiment_{timestamp}.json"
        
        data = {
            "timestamp": timestamp,
            "experiment_type": "GR00T_N1_Metacognitive_Comparison",
            "model_configuration": "single_arm",
            "config": asdict(self.config),
            "groot_client_stats": self.groot_client.get_stats(),
            "results": [asdict(r) for r in self.results]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜: {filename}")

def main():
    """æœ€ç»ˆä¸»å‡½æ•°"""
    print("ğŸ¯ æœ€ç»ˆGR00Tå…ƒè®¤çŸ¥å¯¹æ¯”å®éªŒ")
    print("ä½¿ç”¨æ­£ç¡®çš„å•è‡‚é…ç½®ï¼Œç¡®ä¿æˆåŠŸè°ƒç”¨æ‚¨çš„å¾®è°ƒæ¨¡å‹")
    print("=" * 70)
    
    # é…ç½®
    config = FinalConfig(
        host="localhost",
        port=5555,
        experiment_name="final_groot_metacog_comparison",
        num_episodes=5,
        max_steps_per_episode=50
    )
    
    print(f"å®éªŒé…ç½®:")
    print(f"   GR00TæœåŠ¡: {config.host}:{config.port}")
    print(f"   æ¨¡å‹é…ç½®: å•è‡‚ (single_arm)")
    print(f"   Episodes: {config.num_episodes}")
    print(f"   æœ€å¤§æ­¥æ•°: {config.max_steps_per_episode}")
    
    # è¿è¡Œå®éªŒ
    experiment = FinalGR00TExperiment(config)
    
    try:
        success = experiment.run_experiment()
        if success:
            print(f"\nğŸ‰ æœ€ç»ˆå®éªŒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ”¥ æˆåŠŸè°ƒç”¨æ‚¨å¾®è°ƒçš„GR00T N1æ¨¡å‹")
            print(f"ğŸ§  è·å¾—çœŸå®çš„å…ƒè®¤çŸ¥æ¨¡å—æ•ˆæœå¯¹æ¯”")
            print(f"ğŸ“Š å®éªŒæ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºåˆ†æå’Œè®ºæ–‡")
        else:
            print(f"\nâŒ æœ€ç»ˆå®éªŒå¤±è´¥")
    
    except KeyboardInterrupt:
        print(f"\nâš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®éªŒå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()