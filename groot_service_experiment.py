#!/usr/bin/env python3
"""
ä¿®å¤åçš„GR00Tå®¢æˆ·ç«¯ - ä½¿ç”¨æ­£ç¡®çš„è§†é¢‘åˆ†è¾¨ç‡ (640, 480)
Fixed GR00T Client - Correct Video Resolution (640, 480)
"""

import os
import sys
import time
import json
import numpy as np
import torch
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

# å¯¼å…¥GR00Tå®˜æ–¹å®¢æˆ·ç«¯
try:
    from gr00t.eval.robot import RobotInferenceClient
    GROOT_CLIENT_AVAILABLE = True
    print("âœ… GR00Tå®˜æ–¹å®¢æˆ·ç«¯å¯ç”¨")
except ImportError as e:
    print(f"âŒ GR00Tå®˜æ–¹å®¢æˆ·ç«¯ä¸å¯ç”¨: {e}")
    GROOT_CLIENT_AVAILABLE = False

# # å¯¼å…¥å…ƒè®¤çŸ¥æ¨¡å—
# try:
#     from metacog_integration import (
#         CompleteMetaCognitiveModule,
#         RoboCasaToMetacogAdapter,
#         MetacogToGR00TAdapter,
#         ActionAdjuster,
#         SensorData
#     )
#     METACOG_AVAILABLE = True
#     print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å¯ç”¨")
# except ImportError as e:
#     print(f"âŒ å…ƒè®¤çŸ¥æ¨¡å—ä¸å¯ç”¨: {e}")
#     METACOG_AVAILABLE = False



      
try:
    from metacog_integration import (
        CompleteMetaCognitiveModule,
        RoboCasaToMetacogAdapter,
        MetacogToGR00TAdapter, # è¿™ä¸ªå¯èƒ½ä¸å†ç›´æ¥ç”¨äºè°ƒæ•´GR00TåŠ¨ä½œäº†
        ActionAdjuster,       # åŒä¸Š
        SensorData,
        MetaCognitiveOutput,  # ç¡®ä¿å¯¼å…¥
        DirectiveType,        # ç¡®ä¿å¯¼å…¥
        MetacogToVLASystem2Adapter # æ–°å¢å¯¼å…¥
    )
    METACOG_AVAILABLE = True
    print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å¯ç”¨")
except ImportError as e:
    print(f"âŒ å…ƒè®¤çŸ¥æ¨¡å—ä¸å¯ç”¨: {e}")
    METACOG_AVAILABLE = False

    


@dataclass
class FinalConfig:
    """æœ€ç»ˆå®éªŒé…ç½®"""
    # æœåŠ¡è¿æ¥
    host: str = "localhost"
    port: int = 5555
    
    # å®éªŒè®¾ç½®
    experiment_name: str = "final_groot_experiment"
    num_episodes: int = 8
    max_steps_per_episode: int = 60
    
    # å®éªŒæ¨¡å¼
    run_baseline: bool = True
    run_metacognitive: bool = True
    
    # å…ƒè®¤çŸ¥è®¾ç½®
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

class FixedDataFormatter:
    """ä¿®å¤åçš„æ•°æ®æ ¼å¼å™¨ - ä½¿ç”¨æ­£ç¡®çš„è§†é¢‘åˆ†è¾¨ç‡"""
    
    def __init__(self):
        # æ ¹æ®é”™è¯¯ï¼šæœåŠ¡ç«¯ä»ç„¶æœŸæœ›640x480ï¼Œä¸æ˜¯224x224
        # è™½ç„¶SO100é…ç½®æ˜¯224x224ï¼Œä½†å¾®è°ƒæ¨¡å‹æœŸæœ›640x480
        self.required_keys = {
            "video.webcam": (640, 480, 3),              # æœåŠ¡ç«¯æœŸæœ›ï¼š640x480
            "state.single_arm": (1, 5),                 # 5ä¸ªå…³èŠ‚
            "state.gripper": (1, 1),                    # 1ä¸ªå¤¹çˆªç»´åº¦
            "annotation.human.task_description": None   # ä»»åŠ¡æè¿°
        }
        
        print("ğŸ¯ ä½¿ç”¨å¾®è°ƒæ¨¡å‹æœŸæœ›é…ç½®:")
        for key, shape in self.required_keys.items():
            if shape:
                print(f"   - {key}: {shape}")
            else:
                print(f"   - {key}: [string list]")
    
    def create_correct_observation(self, base_obs: Dict[str, np.ndarray] = None) -> Dict[str, Any]:
        """åˆ›å»ºæ­£ç¡®æ ¼å¼çš„è§‚å¯Ÿæ•°æ®"""
        correct_obs = {}
        
        # 1. è§†é¢‘æ•°æ® - video.webcam (ä¿®æ­£ä¸º height=480, width=640)
        if base_obs and "frontview_image" in base_obs:
            img = base_obs["frontview_image"]
            # ä¿®æ­£ï¼šç¡®ä¿æ˜¯ (height=480, width=640) æ ¼å¼
            if img.shape[:2] != (480, 640):  # (height, width)
                import cv2
                img = cv2.resize(img, (640, 480))  # cv2.resizeä½¿ç”¨ (width, height)
            
            # ç¡®ä¿æ­£ç¡®çš„ç»´åº¦ï¼š(height=480, width=640, channels=3)
            if len(img.shape) == 3:  # (H, W, C)
                correct_obs["video.webcam"] = img.astype(np.uint8)
            else:
                raise ValueError(f"Unexpected image shape: {img.shape}")
        else:
            # ç”Ÿæˆæ­£ç¡®åˆ†è¾¨ç‡çš„æµ‹è¯•å›¾åƒ
            correct_obs["video.webcam"] = self._generate_correct_image()
        
        # 1. è§†é¢‘æ•°æ® - video.webcam (æœåŠ¡ç«¯ä»æœŸæœ›ï¼š640x480)
        if base_obs and "frontview_image" in base_obs:
            img = base_obs["frontview_image"]
            # æœåŠ¡ç«¯æœŸæœ›640x480åˆ†è¾¨ç‡
            if img.shape[:2] != (480, 640):  # (height, width)
                import cv2
                img = cv2.resize(img, (640, 480))  # cv2.resizeä½¿ç”¨ (width, height)
            
            # æ·»åŠ å•ä¸ªbatchç»´åº¦ï¼š(480, 640, 3) â†’ (1, 480, 640, 3)
            if len(img.shape) == 3:
                correct_obs["video.webcam"] = img[np.newaxis, :, :, :].astype(np.uint8)
            else:
                correct_obs["video.webcam"] = img.astype(np.uint8)
        else:
            # ç”Ÿæˆæ­£ç¡®åˆ†è¾¨ç‡çš„æµ‹è¯•å›¾åƒ
            correct_obs["video.webcam"] = self._generate_correct_image()
        
        # 2. å•è‡‚çŠ¶æ€ - state.single_arm (5-DOFï¼Œfloat32)
        if base_obs and "robot0_joint_pos" in base_obs:
            joint_pos = base_obs["robot0_joint_pos"][:5]  # 5ä¸ªå…³èŠ‚
            joint_pos = np.clip(joint_pos, -1.0, 1.0)     # é™åˆ¶å®‰å…¨èŒƒå›´
            correct_obs["state.single_arm"] = joint_pos[np.newaxis, :].astype(np.float32)  # float32
        else:
            # ç”Ÿæˆ5å…³èŠ‚æ•°æ®ï¼Œä½¿ç”¨float32
            joint_data = np.random.uniform(-0.3, 0.3, 5)
            correct_obs["state.single_arm"] = joint_data[np.newaxis, :].astype(np.float32)  # float32
        
        # 3. å¤¹çˆªçŠ¶æ€ - state.gripper (1ç»´ï¼Œfloat32)
        if base_obs and "robot0_gripper_qpos" in base_obs:
            gripper_pos = base_obs["robot0_gripper_qpos"][:1]  # åªå–ç¬¬1ä¸ªç»´åº¦
            correct_obs["state.gripper"] = gripper_pos[np.newaxis, :].astype(np.float32)  # float32
        else:
            # ç”Ÿæˆ1ç»´å¤¹çˆªæ•°æ®ï¼Œä½¿ç”¨float32
            gripper_data = np.random.uniform(-0.1, 0.1, 1)
            correct_obs["state.gripper"] = gripper_data[np.newaxis, :].astype(np.float32)  # float32
        
        # 4. ä»»åŠ¡æè¿° - annotation.human.task_description (æ­£ç¡®çš„key)
        correct_obs["annotation.human.task_description"] = ["Execute SO-100 manipulation task"]
        
        return correct_obs
        
        return correct_obs
    
    def _generate_correct_image(self) -> np.ndarray:
        """ç”Ÿæˆæ­£ç¡®åˆ†è¾¨ç‡çš„æµ‹è¯•å›¾åƒ (640x480)ï¼Œå¸¦å•ä¸ªbatchç»´åº¦"""
        # åˆ›å»ºæœåŠ¡ç«¯æœŸæœ›çš„åˆ†è¾¨ç‡ï¼š(1, 480, 640, 3)
        img = np.zeros((1, 480, 640, 3), dtype=np.uint8)
        
        # åˆ›å»ºæœ‰ç»“æ„çš„å›¾åƒï¼Œé¿å…çº¯éšæœº
        for i in range(480):  # height
            for j in range(640):  # width
                # æ¸å˜æ¨¡å¼
                img[0, i, j, 0] = (i + j) % 256           # Red
                img[0, i, j, 1] = (i * 2) % 256           # Green  
                img[0, i, j, 2] = (j * 2) % 256           # Blue
        
        return img
    
    def print_observation_details(self, obs: Dict[str, Any]):
        """æ‰“å°è§‚å¯Ÿæ•°æ®è¯¦æƒ…"""
        print("ğŸ“Š å‘é€çš„è§‚å¯Ÿæ•°æ®:")
        for key, value in obs.items():
            if isinstance(value, np.ndarray):
                print(f"   {key}: shape={value.shape}, dtype={value.dtype}, range=[{value.min():.3f}, {value.max():.3f}]")
            elif isinstance(value, list):
                print(f"   {key}: list[{len(value)}] = {value}")
            else:
                print(f"   {key}: {type(value)} = {value}")

class FinalGR00TClient:
    """æœ€ç»ˆGR00Tå®¢æˆ·ç«¯"""
    
    def __init__(self, config: FinalConfig):
        self.config = config
        self.client = None
        self.formatter = FixedDataFormatter()  # ä½¿ç”¨ä¿®å¤åçš„æ ¼å¼å™¨
        self.is_connected = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_calls = 0
        self.total_successes = 0
        self.total_failures = 0
        self.total_time = 0.0
    
    def connect(self) -> bool:
        """è¿æ¥åˆ°GR00TæœåŠ¡"""
        if not GROOT_CLIENT_AVAILABLE:
            print("âŒ GR00Tå®˜æ–¹å®¢æˆ·ç«¯ä¸å¯ç”¨")
            return False
        
        try:
            print(f"ğŸ”— è¿æ¥åˆ°GR00TæœåŠ¡: {self.config.host}:{self.config.port}")
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = RobotInferenceClient(
                host=self.config.host, 
                port=self.config.port
            )
            
            # éªŒè¯è¿æ¥
            print("ğŸ“‹ éªŒè¯è¿æ¥...")
            modality_config = self.client.get_modality_config()
            
            print("âœ… è¿æ¥æˆåŠŸï¼æœåŠ¡ç«¯é…ç½®:")
            for key, config in modality_config.items():
                print(f"   - {key}: {config.modality_keys}")
            
            # è¿›è¡Œä¸€æ¬¡æµ‹è¯•è°ƒç”¨ï¼ˆä½¿ç”¨æ­£ç¡®çš„åˆ†è¾¨ç‡ï¼‰
            print("\nğŸ§ª è¿›è¡Œè¿æ¥æµ‹è¯•ï¼ˆä½¿ç”¨å¾®è°ƒæ¨¡å‹æœŸæœ›é…ç½®ï¼š640x480 + float32ï¼‰...")
            test_obs = self.formatter.create_correct_observation()
            self.formatter.print_observation_details(test_obs)
            
            print("ğŸš€ å‘é€æµ‹è¯•è¯·æ±‚...")
            test_result = self.client.get_action(test_obs)
            
            if test_result is not None:
                print("âœ… æµ‹è¯•è°ƒç”¨æˆåŠŸï¼")
                print(f"ğŸ“¤ è¿”å›åŠ¨ä½œé”®: {list(test_result.keys())}")
                for key, value in test_result.items():
                    if isinstance(value, np.ndarray):
                        print(f"   {key}: shape={value.shape}")
                self.is_connected = True
                return True
            else:
                print("âŒ æµ‹è¯•è°ƒç”¨å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def predict(self, observation: Dict[str, np.ndarray]) -> Optional[Dict[str, np.ndarray]]:
        """è¿›è¡Œé¢„æµ‹"""
        if not self.is_connected:
            return None
        
        self.total_calls += 1
        start_time = time.time()
        
        try:
            # åˆ›å»ºæ­£ç¡®æ ¼å¼çš„è§‚å¯Ÿæ•°æ®
            correct_obs = self.formatter.create_correct_observation(observation)
            
            # è°ƒç”¨API
            action = self.client.get_action(correct_obs)
            
            api_time = time.time() - start_time
            self.total_time += api_time
            
            if action is not None:
                self.total_successes += 1
                return action
            else:
                self.total_failures += 1
                return None
                
        except Exception as e:
            api_time = time.time() - start_time
            self.total_time += api_time
            self.total_failures += 1
            print(f"âš ï¸ é¢„æµ‹å¼‚å¸¸: {e}")
            return None
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if self.total_calls == 0:
            return {"calls": 0, "successes": 0, "failures": 0, "success_rate": 0, "avg_time": 0}
        
        return {
            "calls": self.total_calls,
            "successes": self.total_successes,
            "failures": self.total_failures,
            "success_rate": self.total_successes / self.total_calls,
            "avg_time": self.total_time / self.total_calls
        }

@dataclass 
class FinalEpisodeResult:
    """æœ€ç»ˆEpisodeç»“æœ"""
    episode_id: int
    mode: str
    task_success: bool
    total_steps: int
    total_time: float
    api_calls: int
    api_successes: int
    avg_api_time: float
    metacog_interventions: int = 0
    groot_actions_received: int = 0

class FinalGR00TExperiment:
    """æœ€ç»ˆGR00Tå®éªŒ"""
    
    # def __init__(self, config: FinalConfig):
    #     self.config = config
    #     self.groot_client = FinalGR00TClient(config)
    #     self.results = []
        
    #     # è®¾ç½®å…ƒè®¤çŸ¥æ¨¡å—
    #     self.metacog_available = False
    #     if METACOG_AVAILABLE:
    #         try:
    #             self.metacog_module = CompleteMetaCognitiveModule(config.device)
    #             self.robocasa_adapter = RoboCasaToMetacogAdapter(image_size=(480, 640))  # 640x480
    #             self.groot_adapter = MetacogToGR00TAdapter()
    #             self.action_adjuster = ActionAdjuster()
    #             self.metacog_available = True
    #             print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å·²åŠ è½½")
    #         except Exception as e:
    #             print(f"âš ï¸ å…ƒè®¤çŸ¥æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
    #     # åˆ›å»ºç¯å¢ƒ
    #     self.environment = self._create_environment()



class FinalGR00TExperiment:
    def __init__(self, config: FinalConfig):
        self.config = config
        self.groot_client = FinalGR00TClient(config)
        self.results = []

        # è®¾ç½®å…ƒè®¤çŸ¥æ¨¡å—
        self.metacog_available = False
        if METACOG_AVAILABLE:
            try:
                self.metacog_module = CompleteMetaCognitiveModule(config.device)
                self.robocasa_adapter = RoboCasaToMetacogAdapter(image_size=(480, 640))
                # self.groot_adapter = MetacogToGR00TAdapter() # æ—§çš„é€‚é…å™¨ï¼Œå¯èƒ½ä¸å†éœ€è¦
                # self.action_adjuster = ActionAdjuster()     # æ—§çš„è°ƒæ•´å™¨ï¼Œå¯èƒ½ä¸å†éœ€è¦
                self.metacog_to_vla_s2_adapter = MetacogToVLASystem2Adapter() # åˆå§‹åŒ–æ–°çš„é€‚é…å™¨
                self.metacog_available = True
                print("âœ… å…ƒè®¤çŸ¥æ¨¡å—å·²åŠ è½½ (åŒ…å«VLA System2é€‚é…å™¨)")
            except Exception as e:
                print(f"âš ï¸ å…ƒè®¤çŸ¥æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")

        # åˆ›å»ºç¯å¢ƒ
        self.environment = self._create_environment()

    
    def _create_environment(self):
        """åˆ›å»ºå•è‡‚æœºæ¢°æ‰‹ç¯å¢ƒ"""
        class SingleArmTestEnvironment:
            def __init__(self):
                self.step_count = 0
                self.max_steps = 60
                print("ğŸ¤– åˆå§‹åŒ–SO-100æœºæ¢°è‡‚æµ‹è¯•ç¯å¢ƒï¼ˆ640x480åˆ†è¾¨ç‡ï¼Œ5-DOF+1-DOFå¤¹çˆªï¼‰")
            
            def reset(self):
                self.step_count = 0
                return self._generate_obs(), {}
            
            def step(self, action):
                self.step_count += 1
                obs = self._generate_obs()
                
                # å•è‡‚ä»»åŠ¡å®Œæˆé€»è¾‘
                if self.step_count > 25 and np.random.random() < 0.35:
                    done = True
                    reward = 1.0
                elif self.step_count >= self.max_steps:
                    done = True
                    reward = -0.5
                else:
                    done = False
                    reward = np.random.uniform(-0.01, 0.01)
                
                info = {
                    "task_success": done and reward > 0,
                    "collision": np.random.random() < 0.003,
                    "force_violation": np.random.random() < 0.001
                }
                
                return obs, reward, done, False, info
            
            def _generate_obs(self):
                # æœåŠ¡ç«¯å®é™…æœŸæœ›ï¼š640x480åˆ†è¾¨ç‡ + 5å…³èŠ‚ + 1å¤¹çˆª
                return {
                    "frontview_image": np.random.randint(50, 200, (480, 640, 3), dtype=np.uint8),  # 640x480
                    "robot0_joint_pos": np.random.uniform(-0.2, 0.2, 5),     # 5-DOF
                    "robot0_joint_vel": np.random.uniform(-0.1, 0.1, 5),     # 5-DOF å…³èŠ‚é€Ÿåº¦
                    "robot0_gripper_qpos": np.random.uniform(-0.05, 0.05, 1), # 1-DOF å¤¹çˆª
                    "robot0_eef_pos": np.array([0.5, 0.0, 0.8]),             # End effectorä½ç½®
                    "robot0_eef_quat": np.array([0, 0, 0, 1])                # End effectoræ–¹å‘
                }
        
        return SingleArmTestEnvironment()
    
    def run_experiment(self) -> bool:
        """è¿è¡Œæœ€ç»ˆå®éªŒ"""
        print(f"\nğŸ¯ å¼€å§‹ä¿®å¤åçš„GR00Tå…ƒè®¤çŸ¥å¯¹æ¯”å®éªŒ")
        print("ä½¿ç”¨å¾®è°ƒæ¨¡å‹æœŸæœ›é…ç½®ï¼š640x480 + float64 + å•ä¸ªbatchç»´åº¦")
        print("=" * 70)
        
        # è¿æ¥åˆ°GR00TæœåŠ¡
        if not self.groot_client.connect():
            print("âŒ æ— æ³•è¿æ¥åˆ°GR00Tæ¨ç†æœåŠ¡")
            return False
        
        try:
            # è¿è¡ŒåŸºçº¿å®éªŒ
            if self.config.run_baseline:
                print(f"\nğŸ¤– åŸºçº¿å®éªŒ (GR00T N1 å•è‡‚)")
                print("-" * 50)
                
                for episode in range(self.config.num_episodes):
                    print(f"\nğŸ“Š åŸºçº¿ Episode {episode + 1}/{self.config.num_episodes}")
                    result = self._run_episode(episode, "baseline", False)
                    self.results.append(result)
                    self._print_episode_summary(result)
            
            # è¿è¡Œå…ƒè®¤çŸ¥å®éªŒ
            if self.config.run_metacognitive and self.metacog_available:
                print(f"\nğŸ§  å…ƒè®¤çŸ¥å®éªŒ (GR00T N1 + å…ƒè®¤çŸ¥æ¨¡å—)")
                print("-" * 50)
                
                for episode in range(self.config.num_episodes):
                    print(f"\nğŸ“Š å…ƒè®¤çŸ¥ Episode {episode + 1}/{self.config.num_episodes}")
                    result = self._run_episode(episode, "metacognitive", True)
                    self.results.append(result)
                    self._print_episode_summary(result)
            
            # åˆ†æç»“æœ
            self._analyze_results()
            self._save_results()
            
            return True
            
        finally:
            pass
    
    # def _run_episode(self, episode_id: int, mode: str, use_metacognitive: bool) -> FinalEpisodeResult:
    #     """è¿è¡Œæœ€ç»ˆepisode"""
    #     start_time = time.time()
        
    #     result = FinalEpisodeResult(
    #         episode_id=episode_id,
    #         mode=mode,
    #         task_success=False,
    #         total_steps=0,
    #         total_time=0.0,
    #         api_calls=0,
    #         api_successes=0,
    #         avg_api_time=0.0
    #     )
        
    #     try:
    #         obs, info = self.environment.reset()
    #         done = False
    #         step_count = 0
    #         api_times = []
            
    #         print(f"     æ‰§è¡Œä¸­: ", end="", flush=True)
            
    #         while not done and step_count < self.config.max_steps_per_episode:
    #             # è·å–GR00TåŠ¨ä½œ
    #             api_start = time.time()
    #             groot_action = self.groot_client.predict(obs)
    #             api_time = time.time() - api_start
    #             api_times.append(api_time)
                
    #             result.api_calls += 1
                
    #             if groot_action is not None:
    #                 result.api_successes += 1
    #                 result.groot_actions_received += 1
    #                 print(".", end="", flush=True)
    #             else:
    #                 print("x", end="", flush=True)
                
    #             # å…ƒè®¤çŸ¥å¤„ç†
    #             if use_metacognitive and self.metacog_available:
    #                 try:
    #                     sensor_data = self.robocasa_adapter.convert_observation(
    #                         obs, np.random.uniform(-0.03, 0.03, 6)  # å®é™…æœŸæœ›ï¼š6ç»´ï¼ˆ5å…³èŠ‚+1å¤¹çˆªï¼‰
    #                     )
    #                     metacog_output = self.metacog_module.process_sensor_data(sensor_data)
                        
    #                     if metacog_output.directive.value != "continue":
    #                         result.metacog_interventions += 1
    #                         print("M", end="", flush=True)
    #                 except Exception as e:
    #                     pass
                
    #             # ç¯å¢ƒæ­¥è¿›
    #             env_action = np.random.uniform(-0.05, 0.05, 6)  # å®é™…æœŸæœ›ï¼š5ä¸ªå…³èŠ‚ + 1ä¸ªå¤¹çˆª = 6ç»´
    #             obs, reward, done, _, info = self.environment.step(env_action)
    #             step_count += 1
                
    #             if info.get("task_success", False):
    #                 result.task_success = True
    #                 done = True
    #                 print("!", end="", flush=True)
                
    #             # æ¯10æ­¥æ˜¾ç¤ºè¿›åº¦
    #             if step_count % 10 == 0:
    #                 success_rate = result.api_successes / result.api_calls if result.api_calls > 0 else 0
    #                 print(f"|{success_rate:.0%}", end="", flush=True)
            
    #         result.total_steps = step_count
    #         result.total_time = time.time() - start_time
    #         result.avg_api_time = np.mean(api_times) if api_times else 0.0
            
    #         print()  # æ¢è¡Œ
            
    #     except Exception as e:
    #         result.total_time = time.time() - start_time
    #         print(f" å¼‚å¸¸: {e}")
        
    #     return result



    def _run_episode(self, episode_id: int, mode: str, use_metacognitive: bool) -> FinalEpisodeResult:
        start_time = time.time()

        result = FinalEpisodeResult(
            episode_id=episode_id,
            mode=mode,
            task_success=False,
            total_steps=0,
            total_time=0.0,
            api_calls=0,
            api_successes=0,
            avg_api_time=0.0
        )

        try:
            # obs æ˜¯ä»ç¯å¢ƒè·å–çš„åŸå§‹è§‚æµ‹å­—å…¸
            obs, info = self.environment.reset()
            done = False
            step_count = 0
            api_times = []
            
            # ç”¨äºå­˜å‚¨å…ƒè®¤çŸ¥åé¦ˆç»™VLA System2çš„æŒ‡ä»¤
            current_metacognitive_instruction_for_s2 = None

            print(f"     æ‰§è¡Œä¸­ ({mode}): ", end="", flush=True)

            while not done and step_count < self.config.max_steps_per_episode:
                
                # å‡†å¤‡ç»™GR00T/VLAçš„è§‚æµ‹æ•°æ®
                # æˆ‘ä»¬å°†æŠŠå…ƒè®¤çŸ¥æŒ‡ä»¤ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰æ·»åŠ åˆ°è¿™ä¸ªè§‚æµ‹å­—å…¸ä¸­
                observation_for_groot = obs.copy() # ä»ç¯å¢ƒè·å–çš„å½“å‰è§‚æµ‹
                if current_metacognitive_instruction_for_s2:
                    # å‡è®¾VLAçš„System2ä» "metacognitive_instruction" é”®è¯»å–æŒ‡ä»¤
                    # è¿™ä¸ªé”®åéœ€è¦ä¸æ‚¨çš„VLAæ¨¡å‹æœŸæœ›çš„ä¸€è‡´
                    observation_for_groot["metacognitive_instruction"] = [current_metacognitive_instruction_for_s2]
                    # print(f"\nDEBUG: Sending to GR00T with instruction: {current_metacognitive_instruction_for_s2}")
                else:
                    # å¦‚æœæ²¡æœ‰æŒ‡ä»¤ï¼Œå¯ä»¥ä¸æ·»åŠ è¯¥é”®ï¼Œæˆ–è€…æ·»åŠ ä¸€ä¸ªç©ºåˆ—è¡¨/å ä½ç¬¦
                    # observation_for_groot["metacognitive_instruction"] = [] # å–å†³äºVLAå¦‚ä½•å¤„ç†
                    pass


                # è·å–GR00T/VLAåŠ¨ä½œ
                api_start = time.time()
                # ä½¿ç”¨åŒ…å«ï¼ˆå¯èƒ½æœ‰çš„ï¼‰å…ƒè®¤çŸ¥æŒ‡ä»¤çš„è§‚æµ‹æ•°æ®è¿›è¡Œé¢„æµ‹
                groot_action_dict = self.groot_client.predict(observation_for_groot)
                api_time = time.time() - api_start
                api_times.append(api_time)

                result.api_calls += 1
                current_metacognitive_instruction_for_s2 = None # æ¸…é™¤ä¸Šä¸€æ¡æŒ‡ä»¤ï¼Œç­‰å¾…æ–°çš„

                if groot_action_dict is not None:
                    result.api_successes += 1
                    result.groot_actions_received += 1
                    print(".", end="", flush=True)
                    # ä»GR00Tè¿”å›çš„å­—å…¸ä¸­æå–å®é™…çš„åŠ¨ä½œ (å‡è®¾æ˜¯è¿™æ ·)
                    # æ‚¨éœ€è¦æ ¹æ®groot_action_dictçš„å®é™…ç»“æ„æ¥æå–ç”¨äºç¯å¢ƒstepçš„åŠ¨ä½œ
                    # ä¾‹å¦‚ï¼š env_action = groot_action_dict.get("action", np.random.uniform(-0.05, 0.05, 6))
                    # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ç»§ç»­ç”¨éšæœºåŠ¨ä½œï¼Œä½†ç†æƒ³æƒ…å†µä¸‹è¿™é‡Œåº”è¯¥æ˜¯GR00Tçš„åŠ¨ä½œ
                    env_action_to_execute = np.random.uniform(-0.05, 0.05, 6)
                    # è·å–System1æ‰§è¡Œçš„åŠ¨ä½œä¿¡æ¯ï¼Œç”¨äºå…ƒè®¤çŸ¥æ¨¡å—
                    # å¦‚æœgroot_action_dictåŒ…å«è¯¦ç»†çš„åŠ¨ä½œå‚æ•°ï¼Œå¯ä»¥ç”¨å®ƒ
                    # å¦åˆ™ï¼Œå¯ä»¥ç”¨ env_action_to_execute
                    s1_action_info_for_metacog = env_action_to_execute
                else:
                    print("x", end="", flush=True)
                    # å¦‚æœGR00Tæ²¡æœ‰è¿”å›åŠ¨ä½œï¼Œä¹Ÿéœ€è¦ä¸€ä¸ªåŠ¨ä½œç»™ç¯å¢ƒ
                    env_action_to_execute = np.random.uniform(-0.05, 0.05, 6)
                    s1_action_info_for_metacog = env_action_to_execute


                # ç¯å¢ƒæ­¥è¿›ï¼Œä½¿ç”¨ env_action_to_execute
                # obs åœ¨è¿™é‡Œè¢«æ›´æ–°ä¸ºä¸‹ä¸€æ­¥çš„è§‚æµ‹
                next_obs, reward, done, _, info = self.environment.step(env_action_to_execute)


                # å…ƒè®¤çŸ¥å¤„ç† (åŸºäº next_obs å’Œ s1_action_info_for_metacog)
                if use_metacognitive and self.metacog_available:
                    try:
                        # ä½¿ç”¨æ‰§è¡ŒåŠ¨ä½œåçš„æ–°è§‚æµ‹ next_obs å’Œ System1çš„åŠ¨ä½œä¿¡æ¯
                        sensor_data = self.robocasa_adapter.convert_observation(
                            next_obs, # ä½¿ç”¨æ‰§è¡ŒåŠ¨ä½œåçš„æ–°è§‚æµ‹
                            s1_action_info_for_metacog, # System1æ‰§è¡Œçš„åŠ¨ä½œæˆ–å…¶è¯¦ç»†ä¿¡æ¯
                            execution_status="normal" # å¯ä»¥æ ¹æ®å®é™…æƒ…å†µæ›´æ–°
                        )
                        metacog_output = self.metacog_module.process_sensor_data(sensor_data)
                        
                        # ç”Ÿæˆç»™System2çš„ç®€ç»ƒæŒ‡ä»¤
                        instruction_for_s2 = self.metacog_to_vla_s2_adapter.convert_to_system2_instruction(metacog_output)

                        if instruction_for_s2:
                            current_metacognitive_instruction_for_s2 = instruction_for_s2
                            # ä»…åœ¨ç”Ÿæˆäº†æœ‰æ•ˆæŒ‡ä»¤æ—¶æ‰ç®—ä½œå¹²é¢„å¹¶æ‰“å°
                            if metacog_output.directive != DirectiveType.CONTINUE: # ç¡®ä¿ä¸æ˜¯CONTINUEæŒ‡ä»¤
                                result.metacog_interventions += 1
                                print(f"M[{instruction_for_s2[:15]}..]", end="", flush=True) # æ‰“å°æŒ‡ä»¤çš„ç®€çŸ­å½¢å¼
                        
                    except Exception as e:
                        print(f"\nå…ƒè®¤çŸ¥å¤„ç†å¼‚å¸¸: {e}")
                        pass
                
                obs = next_obs # æ›´æ–°è§‚æµ‹ä»¥ä¾›ä¸‹ä¸€è½®å¾ªç¯ä½¿ç”¨

                step_count += 1

                if info.get("task_success", False):
                    result.task_success = True
                    done = True
                    print("!", end="", flush=True)

                if step_count % 10 == 0 and result.api_calls > 0:
                    success_rate = result.api_successes / result.api_calls
                    print(f"|{success_rate:.0%}", end="", flush=True)
            
            result.total_steps = step_count
            result.total_time = time.time() - start_time
            result.avg_api_time = np.mean(api_times) if api_times else 0.0
            
            print() # æ¢è¡Œ
            
        except Exception as e:
            result.total_time = time.time() - start_time
            print(f" å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc() # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
        
        return result


    
    def _print_episode_summary(self, result: FinalEpisodeResult):
        """æ‰“å°æœ€ç»ˆepisodeæ‘˜è¦"""
        status = "âœ… æˆåŠŸ" if result.task_success else "âŒ å¤±è´¥"
        api_success_rate = result.api_successes / result.api_calls if result.api_calls > 0 else 0
        
        print(f"   ç»“æœ: {status}")
        print(f"   æ‰§è¡Œ: {result.total_steps} æ­¥, {result.total_time:.1f}s")
        print(f"   API: {result.api_successes}/{result.api_calls} æˆåŠŸ ({api_success_rate:.1%}), "
              f"å¹³å‡ {result.avg_api_time*1000:.1f}ms")
        print(f"   GR00TåŠ¨ä½œ: {result.groot_actions_received} ä¸ª")
        
        if result.metacog_interventions > 0:
            print(f"   å…ƒè®¤çŸ¥: {result.metacog_interventions} æ¬¡å¹²é¢„")
    
    def _analyze_results(self):
        """åˆ†ææœ€ç»ˆå®éªŒç»“æœ"""
        print(f"\nğŸ“Š æœ€ç»ˆå®éªŒç»“æœåˆ†æ")
        print("=" * 70)
        
        baseline_results = [r for r in self.results if r.mode == "baseline"]
        metacog_results = [r for r in self.results if r.mode == "metacognitive"]
        
        def analyze_mode(results: List[FinalEpisodeResult], mode_name: str):
            if not results:
                return
            
            successes = sum(1 for r in results if r.task_success)
            success_rate = successes / len(results)
            total_api_calls = sum(r.api_calls for r in results)
            total_api_successes = sum(r.api_successes for r in results)
            api_success_rate = total_api_successes / total_api_calls if total_api_calls > 0 else 0
            total_groot_actions = sum(r.groot_actions_received for r in results)
            avg_api_time = np.mean([r.avg_api_time for r in results])
            
            print(f"\nğŸ” {mode_name} æ¨¡å¼åˆ†æ:")
            print(f"   ä»»åŠ¡æˆåŠŸç‡: {success_rate:.1%} ({successes}/{len(results)})")
            print(f"   APIæˆåŠŸç‡: {api_success_rate:.1%} ({total_api_successes}/{total_api_calls})")
            print(f"   æœ‰æ•ˆGR00TåŠ¨ä½œ: {total_groot_actions}")
            print(f"   å¹³å‡APIå“åº”æ—¶é—´: {avg_api_time*1000:.1f}ms")
            
            if api_success_rate > 0.8:
                print(f"   ğŸ‰ å®Œç¾ï¼æˆåŠŸè°ƒç”¨æ‚¨çš„å¾®è°ƒGR00T N1æ¨¡å‹")
            elif api_success_rate > 0.5:
                print(f"   ğŸ‘ è‰¯å¥½ï¼å¤§éƒ¨åˆ†APIè°ƒç”¨æˆåŠŸ")
            elif api_success_rate > 0:
                print(f"   ğŸ”§ éƒ¨åˆ†æˆåŠŸï¼Œä»éœ€ä¼˜åŒ–")
            else:
                print(f"   âŒ APIè°ƒç”¨å¤±è´¥")
            
            if mode_name == "å…ƒè®¤çŸ¥":
                total_interventions = sum(r.metacog_interventions for r in results)
                print(f"   å…ƒè®¤çŸ¥å¹²é¢„æ€»æ•°: {total_interventions}")
        
        analyze_mode(baseline_results, "åŸºçº¿")
        analyze_mode(metacog_results, "å…ƒè®¤çŸ¥")
        
        # å¯¹æ¯”åˆ†æ
        if baseline_results and metacog_results:
            print(f"\nâš–ï¸ å¯¹æ¯”åˆ†æ:")
            
            baseline_success = sum(1 for r in baseline_results if r.task_success) / len(baseline_results)
            metacog_success = sum(1 for r in metacog_results if r.task_success) / len(metacog_results)
            success_improvement = metacog_success - baseline_success
            
            print(f"   ä»»åŠ¡æˆåŠŸç‡å˜åŒ–: {success_improvement:+.1%}")
            
            if success_improvement > 0:
                print(f"   âœ… å…ƒè®¤çŸ¥æ¨¡å—æå‡äº†ä»»åŠ¡æˆåŠŸç‡")
            elif success_improvement == 0:
                print(f"   â¡ï¸ å…ƒè®¤çŸ¥æ¨¡å—ä¿æŒäº†ä»»åŠ¡æˆåŠŸç‡")
            else:
                print(f"   âš ï¸ å…ƒè®¤çŸ¥æ¨¡å—é™ä½äº†ä»»åŠ¡æˆåŠŸç‡")
        
        # GR00TæœåŠ¡æœ€ç»ˆè¯„ä¼°
        client_stats = self.groot_client.get_stats()
        print(f"\nğŸ“¡ GR00TæœåŠ¡æœ€ç»ˆè¯„ä¼°:")
        print(f"   æ€»APIè°ƒç”¨: {client_stats['calls']}")
        print(f"   APIæˆåŠŸç‡: {client_stats['success_rate']:.1%}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {client_stats['avg_time']*1000:.1f}ms")
        
        if client_stats['success_rate'] >= 0.9:
            print(f"   ğŸ‰ å®Œç¾ï¼æ‚¨çš„å¾®è°ƒGR00T N1æ¨¡å‹å·¥ä½œä¼˜ç§€")
        elif client_stats['success_rate'] >= 0.7:
            print(f"   ğŸ‘ ä¼˜ç§€ï¼æ‚¨çš„å¾®è°ƒGR00T N1æ¨¡å‹å·¥ä½œè‰¯å¥½")
        elif client_stats['success_rate'] >= 0.5:
            print(f"   ğŸ“ˆ è‰¯å¥½ï¼APIè°ƒç”¨åŸºæœ¬ç¨³å®š")
        elif client_stats['success_rate'] > 0:
            print(f"   ğŸ”§ æœ‰è¿›å±•ï¼éƒ¨åˆ†APIè°ƒç”¨æˆåŠŸ")
        else:
            print(f"   ğŸ› ï¸ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    def _save_results(self):
        """ä¿å­˜æœ€ç»ˆå®éªŒç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"fixed_groot_experiment_{timestamp}.json"
        
        data = {
            "timestamp": timestamp,
            "experiment_type": "GR00T_N1_Metacognitive_Comparison_Fixed",
            "model_configuration": "so100_finetuned_640x480_float32",
            "config": asdict(self.config),
            "groot_client_stats": self.groot_client.get_stats(),
            "results": [asdict(r) for r in self.results]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜: {filename}")

def main():
    """ä¿®å¤åçš„ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¿®å¤åçš„GR00Tå…ƒè®¤çŸ¥å¯¹æ¯”å®éªŒ")
    print("ä½¿ç”¨å¾®è°ƒæ¨¡å‹æœŸæœ›é…ç½®ï¼š640x480åˆ†è¾¨ç‡ + float32 + å•ä¸ªbatchç»´åº¦")
    print("=" * 70)
    
    # é…ç½®
    config = FinalConfig(
        host="localhost",
        port=5555,
        experiment_name="fixed_groot_metacog_comparison",
        num_episodes=3,  # å…ˆç”¨å°‘é‡episodeæµ‹è¯•
        max_steps_per_episode=50
    )
    
    print(f"å®éªŒé…ç½®:")
    print(f"   GR00TæœåŠ¡: {config.host}:{config.port}")
    print(f"   æ¨¡å‹é…ç½®: å•è‡‚ (single_arm)")
    print(f"   è§†é¢‘åˆ†è¾¨ç‡: 640x480 (ä¿®æ­£)")
    print(f"   Episodes: {config.num_episodes}")
    print(f"   æœ€å¤§æ­¥æ•°: {config.max_steps_per_episode}")
    
    # è¿è¡Œå®éªŒ
    experiment = FinalGR00TExperiment(config)
    
    try:
        success = experiment.run_experiment()
        if success:
            print(f"\nğŸ‰ ä¿®å¤åçš„å®éªŒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ”¥ æˆåŠŸè°ƒç”¨æ‚¨å¾®è°ƒçš„GR00T N1æ¨¡å‹")
            print(f"ğŸ§  è·å¾—çœŸå®çš„å…ƒè®¤çŸ¥æ¨¡å—æ•ˆæœå¯¹æ¯”")
            print(f"ğŸ“Š å®éªŒæ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºåˆ†æå’Œè®ºæ–‡")
        else:
            print(f"\nâŒ å®éªŒå¤±è´¥")
    
    except KeyboardInterrupt:
        print(f"\nâš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®éªŒå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()